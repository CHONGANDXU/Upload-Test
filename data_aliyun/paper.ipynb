{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进入 21 世纪，生命科学特别是基因科技已经广泛而且深刻影响到每个人的健康生活，于此同时，科学家们借助基因科技史无前例的用一种全新的视角解读生命和探究疾病本质。人工智能（AI）能够处理分析海量医疗健康数据，通过认知分析获取洞察，服务于政府、健康医疗机构、制药企业及患者，实现个性化，可以循证的智慧医疗，推动创新，实现价值。\n",
    "\n",
    "心血管病、糖尿病等慢性疾病，每年导致的死亡人数占总死亡人数的 80%，每年用于慢病医疗费用占中国公共医疗卫生支出的比例超过 13%。作为一种常见慢性疾病，糖尿病目前无法根治，但却能通过科学有效的干预、预防和治疗，来降低发病率和提高患者的生活质量。阿里云联合青梧桐健康科技有限公司主办天池精准医疗大赛——人工智能辅助糖尿病遗传风险预测，希望用人工智能的方法和思想处理、分析、解读和应用糖尿病相关大数据，让参赛选手设计高精度，高效，且解释性强的算法来挑战糖尿病精准预测这一科学难题，为学术界和精准医疗提供有力的技术支撑，帮助我们攻克糖尿病。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Heiti TC\"]  # 用来正常显示中文标签\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 用来正常显示负号\n",
    "\n",
    "train_data = pd.read_csv(\"./data/d_train_20180102.csv\", encoding=\"utf-8\")\n",
    "test_data = pd.read_csv(\"./data/d_test_A_20180102.csv\", encoding=\"utf-8\")\n",
    "test_data[\"血糖\"] = pd.read_csv(\"./data/d_answer_a_20180128.csv\", encoding=\"utf-8\")\n",
    "data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据概况\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整体数据集的大概分布情况\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始数据集的年龄分布直方图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9), dpi=400)\n",
    "\n",
    "n, bins_num, patches = ax.hist(data[\"年龄\"], bins=10, alpha=0.75, edgecolor=\"white\")\n",
    "\n",
    "ax.plot(bins_num[:10], n, marker=\"o\", color=\"yellowgreen\", linestyle=\"--\")\n",
    "\n",
    "for i in range(len(n)):\n",
    "    plt.text(\n",
    "        x=bins_num[i] + (bins_num[1] - bins_num[0]) / 2,\n",
    "        y=n[i] * 1.01,\n",
    "        s=str(int(n[i])),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=20,\n",
    "    )\n",
    "\n",
    "print(\"频数:{}\\n区间:{}\".format(n, bins_num))\n",
    "\n",
    "min_age = data[\"年龄\"].min()\n",
    "max_age = data[\"年龄\"].max()\n",
    "\n",
    "t1 = np.linspace(min_age, max_age, num=11)\n",
    "\n",
    "plt.xticks(t1)\n",
    "plt.tick_params(labelsize=18)\n",
    "plt.xlabel(\"年龄区间（分组）\", fontdict={\"weight\": \"normal\", \"size\": 20})\n",
    "plt.ylabel(\"频数\", fontdict={\"weight\": \"normal\", \"size\": 20})\n",
    "plt.title(\"初始数据集的年龄分布——直方图\", fontdict={\"weight\": \"normal\", \"size\": 20})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始数据集的血糖分布图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9), dpi=400)\n",
    "\n",
    "# 设置图形的总体风格\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# 创建分布图\n",
    "displot = sns.displot(\n",
    "    data,\n",
    "    x=\"血糖\",\n",
    "    kde=False,\n",
    "    stat=\"density\",\n",
    "    kind=\"hist\",\n",
    "    bins=100,\n",
    "    color=\"blue\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "\n",
    "# 设置图形的标题和轴标签\n",
    "displot.set(title=\"Distribution of Variable\", xlabel=\"Value\", ylabel=\"Frequency\")\n",
    "\n",
    "# 调整子图间距和边缘间距\n",
    "plt.subplots_adjust(top=0.9, bottom=0.1, left=0.1, right=0.9)\n",
    "\n",
    "(mu, sigma) = norm.fit(data[\"血糖\"])  # mu均值  sigma方差\n",
    "\n",
    "print(\"\\n mu = {:.3f} and sigma = {:.3f}\\n\".format(mu, sigma))\n",
    "\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, p, \"k\", linewidth=1)\n",
    "\n",
    "plt.legend(\n",
    "    [r\"Normal distribution ($\\mu={:.3f}, \\sigma={:.3f}$)\".format(mu, sigma)],\n",
    "    loc=\"best\",\n",
    "    prop={\"size\": 10},\n",
    ")\n",
    "\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始数据集的数据缺失情况\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每一列缺失值的百分比\n",
    "missing_rate = (data.isnull().sum() / data.shape[0] * 100).sort_values(ascending=False)\n",
    "# 将结果转换为dataframe\n",
    "missing_rate_df = pd.DataFrame(missing_rate, columns=[\"Missing_Ratio(%)\"])\n",
    "missing_rate_df[\"Missing_Ratio(%)\"] = missing_rate_df[\"Missing_Ratio(%)\"].round(4)\n",
    "# 重置索引，将列名作为一列\n",
    "missing_rate_df = missing_rate_df.reset_index().rename(columns={\"index\": \"col_name\"})\n",
    "missing_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "plt.subplots(figsize=(18, 10), dpi=400)\n",
    "\n",
    "plt.barh(\n",
    "    missing_rate_df[\"col_name\"],\n",
    "    missing_rate_df[\"Missing_Ratio(%)\"],\n",
    "    color=[\n",
    "        f\"#{random.randint(0, 255):02x}{random.randint(0, 255):02x}{random.randint(0, 255):02x}\"\n",
    "        for _ in range(len(data))\n",
    "    ],\n",
    ")\n",
    "\n",
    "for i, v in enumerate(missing_rate_df[\"Missing_Ratio(%)\"]):\n",
    "    plt.text(v + 0.1, i, str(v), va=\"center\")\n",
    "\n",
    "plt.xlabel(\"缺失比率\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "年龄转换成分类数值变量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(data[\"性别\"])\n",
    "label = le.transform(data[\"性别\"])  # transform接口调取结果\n",
    "print(le.classes_)  # 属性.classes_查看标签中究竟有多少类别\n",
    "\n",
    "data = data.drop(data[data[\"性别\"] == \"??\"].index)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(data[\"性别\"])\n",
    "label = le.transform(data[\"性别\"])  # transform接口调取结果\n",
    "print(le.classes_)  # 属性.classes_查看标签中究竟有多少类别\n",
    "\n",
    "data[\"性别\"] = LabelEncoder().fit_transform(data.loc[:, \"性别\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一条性别数据为未知，删除后再进行分类，女标签为 0 ，男标签为 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- drop id 与 体检日期 两列数据【与预测值没有关系】\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=[\"id\", \"体检日期\"], axis=1)\n",
    "\n",
    "test_data = test_data.drop(columns=[\"id\", \"体检日期\"], axis=1)\n",
    "\n",
    "data = data.drop(columns=[\"id\", \"体检日期\"], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 乙肝两对半的五项指标，缺失值太多，相关性很低，考虑丢弃\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(\n",
    "    columns=[\"乙肝表面抗原\", \"乙肝表面抗体\", \"乙肝e抗原\", \"乙肝e抗体\", \"乙肝核心抗体\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "test_data = test_data.drop(\n",
    "    columns=[\"乙肝表面抗原\", \"乙肝表面抗体\", \"乙肝e抗原\", \"乙肝e抗体\", \"乙肝核心抗体\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "data = data.drop(\n",
    "    columns=[\"乙肝表面抗原\", \"乙肝表面抗体\", \"乙肝e抗原\", \"乙肝e抗体\", \"乙肝核心抗体\"],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "连续变量，诸多测量变量的箱型图，排除了'性别','年龄','乙肝表面抗原','乙肝表面抗体', '乙肝 e 抗原', '乙肝 e 抗体', '乙肝核心抗体'\n",
    "\n",
    "- 性别 为 分类变量，不适用箱型图\n",
    "- 年龄 不是 测量变量\n",
    "- '乙肝表面抗原','乙肝表面抗体', '乙肝 e 抗原', '乙肝 e 抗体', '乙肝核心抗体' 缺失情况太严重，不做箱型图\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "删除缺失值较多的行，这里使用 20%为界限  \n",
    "其余 NAN 值使用该属性列的均值填充\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每一行缺失值的比率\n",
    "missing_count = data.isna().sum(axis=1)\n",
    "missing_ratio = missing_count / len(data.columns)\n",
    "\n",
    "# 筛选需要删除的行\n",
    "to_drop = missing_ratio[missing_ratio > 0.2].index\n",
    "data.drop(to_drop, inplace=True)\n",
    "\n",
    "# 用平均值填充剩余的缺失值\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再次查看数据矩阵的分布情况\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15, 9), dpi=400)\n",
    "\n",
    "ax = sns.boxenplot(\n",
    "    data=data.loc[\n",
    "        :,\n",
    "        [\n",
    "            \"*天门冬氨酸氨基转换酶\",\n",
    "            \"*丙氨酸氨基转换酶\",\n",
    "            \"*碱性磷酸酶\",\n",
    "            \"*r-谷氨酰基转换酶\",\n",
    "            \"尿酸\",\n",
    "            \"血红蛋白\",\n",
    "            \"红细胞平均血红蛋白浓度\",\n",
    "            \"血小板计数\",\n",
    "        ],\n",
    "    ],\n",
    "    outlier_prop=0.05,\n",
    "    palette=\"Set2\",\n",
    "    linewidth=0.25,\n",
    ")\n",
    "plt.setp(ax.get_xticklabels(), rotation=15)\n",
    "plt.tick_params(labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15, 9), dpi=400)\n",
    "cols = [\n",
    "    i\n",
    "    for i in data.columns\n",
    "    if i\n",
    "    not in [\n",
    "        \"*天门冬氨酸氨基转换酶\",\n",
    "        \"*丙氨酸氨基转换酶\",\n",
    "        \"*碱性磷酸酶\",\n",
    "        \"*r-谷氨酰基转换酶\",\n",
    "        \"尿酸\",\n",
    "        \"血红蛋白\",\n",
    "        \"红细胞平均血红蛋白浓度\",\n",
    "        \"血小板计数\",\n",
    "        \"性别\",\n",
    "        \"血糖\",\n",
    "    ]\n",
    "]\n",
    "ax = sns.boxenplot(data[cols], outlier_prop=0.03, palette=\"Set2\", linewidth=0.25)\n",
    "plt.setp(ax.get_xticklabels(), rotation=65)\n",
    "plt.tick_params(labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data[data[\"*天门冬氨酸氨基转换酶\"] > 200].index)\n",
    "data = data.drop(data[data[\"*丙氨酸氨基转换酶\"] > 250].index)\n",
    "data = data.drop(data[data[\"*r-谷氨酰基转换酶\"] > 600].index)\n",
    "data = data.drop(data[data[\"血小板计数\"] > 600].index)\n",
    "data = data.drop(data[data[\"*球蛋白\"] > 60].index)\n",
    "data = data.drop(data[data[\"甘油三酯\"] > 30].index)\n",
    "data = data.drop(data[data[\"肌酐\"] > 175].index)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('drop_fillna.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多重线性回归分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "x = sm.add_constant(data.iloc[:, :-1])\n",
    "y = data[\"血糖\"]\n",
    "model = sm.OLS(y, x).fit()  # 拟合模型\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是使用Pandas、NumPy和StatsModels库进行多重线性回归模型评估的代码：\n",
    "\n",
    "# 计算均方误差（MSE）和决定系数（R²）：\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 计算预测值\n",
    "y_pred = model.predict(x)\n",
    "\n",
    "# 计算MSE\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "# 计算R²\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "# 打印MSE和R²\n",
    "print(\"MSE: \", mse)\n",
    "print(\"R²: \", r2)\n",
    "# 在上述代码中，我们首先使用predict()函数计算回归模型的预测值，然后使用mean_squared_error()函数计算均方误差，使用r2_score()函数计算决定系数，并打印出结果。\n",
    "\n",
    "# 绘制残差图和QQ图：\n",
    "\n",
    "# 计算残差\n",
    "residuals = y - y_pred\n",
    "\n",
    "# 绘制残差图\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"-\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n",
    "\n",
    "# 绘制QQ图\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot\")\n",
    "plt.show()\n",
    "# 在上述代码中，我们首先计算残差，然后使用scatter()函数绘制残差图。我们还通过axhline()函数添加了一条水平线，以帮助我们评估残差是否随机分布。接下来，我们使用probplot()函数绘制QQ图，以评估残差是否服从正态分布。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据标准化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset = data.iloc[:, :-1]\n",
    "print(dataset.shape)\n",
    "# print(dataset.isnull().sum())\n",
    "target = data.iloc[:, -1]\n",
    "print(target.shape)\n",
    "# print(target.isnull().sum())\n",
    "\n",
    "z_score = pd.DataFrame(StandardScaler().fit_transform(dataset), columns=dataset.columns)\n",
    "\n",
    "z_score[\"性别\"] = z_score[\"性别\"].astype(\"int32\")\n",
    "z_score[\"年龄\"] = z_score[\"年龄\"].astype(\"int64\")\n",
    "\n",
    "z_score.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(alpha=0.05)\n",
    "\n",
    "# 训练模型\n",
    "model.fit(z_score, target)\n",
    "\n",
    "# 输出特征重要性\n",
    "importances = pd.DataFrame({\"feature\": z_score.columns, \"importance\": abs(model.coef_)})\n",
    "importances = importances.sort_values(\"importance\", ascending=False).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "importances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "热力图相关性分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(z_score.corr(), dtype=np.bool_)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "fig_corr, ax_corr = plt.subplots(figsize=(28, 24), dpi=400)\n",
    "\n",
    "cmap = sns.diverging_palette(250, 5, as_cmap=True)\n",
    "\n",
    "# seaborn.diverging_palette(h_neg, h_pos, s=75, l=50, sep=1, n=6, center='light', as_cmap=False)\n",
    "# Make a diverging palette between two HUSL colors.\n",
    "# Parameters:\n",
    "# h_neg, h_pos : float in [0, 359]\n",
    "# Anchor hues for negative and positive extents of the map\n",
    "# as_cmap : bool, optional\n",
    "# If True, return a matplotlib.colors.ListedColormap\n",
    "\n",
    "sns.heatmap(\n",
    "    data=z_score.corr(),\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    center=0,\n",
    "    fmt=\".2f\",\n",
    "    square=True,\n",
    "    annot=True,\n",
    "    linewidth=0.5,\n",
    "    ax=ax_corr,\n",
    "    annot_kws={\"fontsize\": 14},\n",
    ")\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score = z_score.drop(\n",
    "    columns=[\n",
    "        \"*天门冬氨酸氨基转换酶\",\n",
    "        \"总胆固醇\",\n",
    "        \"红细胞压积\",\n",
    "        \"血红蛋白\",\n",
    "        \"血小板比积\",\n",
    "        \"红细胞平均血红蛋白量\",\n",
    "        \"白球比例\",\n",
    "        \"中性粒细胞%\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "print(z_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "\n",
    "# Bartlett's球状检验\n",
    "chi_square_value, p_value = calculate_bartlett_sphericity(z_score)\n",
    "print(\"Bartlett球状检验卡方值:{}\\nP值:{}\".format(chi_square_value, p_value))\n",
    "print()\n",
    "\n",
    "# KMO检验\n",
    "# 检查变量间的相关性和偏相关性，取值在0-1之间；KMO统计量越接近1，变量间的相关性越强，偏相关性越弱，因子分析的效果越好。\n",
    "# 通常取值从0.6开始进行因子分析\n",
    "\n",
    "kmo_all, kmo_model = calculate_kmo(z_score)\n",
    "print(\"KMO检验参数\\n\", kmo_all)\n",
    "print(kmo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=26)\n",
    "pca.fit(z_score)\n",
    "variance = pca.explained_variance_ratio_\n",
    "var = np.cumsum(np.round(variance, 3) * 100)\n",
    "print(var)\n",
    "plt.figure(figsize=(8, 4), dpi=400)\n",
    "plt.ylabel(\"Variance Explained\")\n",
    "plt.xlabel(\"Number of Features\")\n",
    "plt.title(\"PCA Analysis\")\n",
    "plt.ylim(10, 110)\n",
    "plt.plot(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.98, svd_solver=\"full\")\n",
    "pca.fit(z_score)\n",
    "variance = pca.explained_variance_ratio_\n",
    "var = np.cumsum(np.round(variance, 3) * 100)\n",
    "print(var)\n",
    "\n",
    "column = [\n",
    "    \"component1\",\n",
    "    \"component2\",\n",
    "    \"component3\",\n",
    "    \"component4\",\n",
    "    \"component5\",\n",
    "    \"component6\",\n",
    "    \"component7\",\n",
    "    \"component8\",\n",
    "    \"component9\",\n",
    "    \"component10\",\n",
    "    \"component11\",\n",
    "    \"component12\",\n",
    "    \"component13\",\n",
    "    \"component14\",\n",
    "    \"component15\",\n",
    "    \"component16\",\n",
    "    \"component17\",\n",
    "    \"component18\",\n",
    "    \"component19\",\n",
    "    \"component20\",\n",
    "    \"component21\",\n",
    "    \"component22\",\n",
    "    \"component23\",\n",
    "]\n",
    "pca_trans = pca.transform(z_score)\n",
    "pca_df = pd.DataFrame(pca_trans, columns=column)\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_df.to_csv('z_score_pca.csv')\n",
    "# target.to_csv('target.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练集测试集划分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"z_score_pca.csv\", index_col=0)\n",
    "target = pd.read_csv(\"target.csv\", index_col=0)\n",
    "print(df.shape)\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    df, target, test_size=0.3, random_state=23\n",
    ")\n",
    "\n",
    "train_labels = train_labels.values.ravel()\n",
    "test_labels = test_labels.values.ravel()\n",
    "\n",
    "print(train_features.shape, train_labels.shape)\n",
    "print(test_features.shape, test_labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多重线性回归\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "LinearR = linear_model.LinearRegression()\n",
    "model = LinearR.fit(train_features, train_labels)\n",
    "prediction_train = LinearR.predict(train_features)\n",
    "print(\"训练集的MSE为:{}\".format(mean_squared_error(train_labels, prediction_train)))\n",
    "print(\"训练集的R2为:{}\".format(r2_score(train_labels, prediction_train)))\n",
    "prediction_test = LinearR.predict(test_features)\n",
    "print(\"测试集的MSE为:{}\".format(mean_squared_error(test_labels, prediction_test)))\n",
    "print(\"测试集的R2为:{}\".format(r2_score(test_labels, prediction_test)))\n",
    "\n",
    "# coef_ 系数w1,w2.....wn\n",
    "print(LinearR.coef_)\n",
    "\n",
    "# intercept_ 截距\n",
    "print(LinearR.intercept_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # 深度神经网络\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, PReLU, Dropout, BatchNormalization\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.keras.utils.custom_object_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [  # 根据情况调整模型结构，Sequential模型，可进行层的堆叠\n",
    "        Dense(units=400, input_dim=train_features.shape[1], activation=PReLU()),\n",
    "        Dropout(0.4),\n",
    "        Dense(units=160, kernel_initializer=\"normal\", activation=PReLU()),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.6),\n",
    "        Dense(units=64, kernel_initializer=\"normal\", activation=PReLU()),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(units=26, kernel_initializer=\"normal\", activation=PReLU()),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.6),\n",
    "        Dense(1, kernel_initializer=\"normal\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Dense(units,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None)\n",
    "# units：大于0的整数，代表该层的输出维度\n",
    "# input_dim：该层输入的维度\n",
    "# activation：激活函数，为预定义的激活函数名（参考激活函数），或逐元素（element-wise）的Theano函数。如果不指定该参数，将不会使用任何激活函数（即使用线性激活函数：a(x)=x）\n",
    "\n",
    "# use_bias：布尔值，是否使用偏置项\n",
    "# kernel_initializer：权值初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的初始化器。\n",
    "# bias_initializer：偏置向量初始化方法，为预定义初始化方法名的字符串，或用于初始化偏置向量的初始化器。\n",
    "# regularizer：正则项，kernel为权重的、bias为偏执的，activity为输出的\n",
    "# constraints：约束项，kernel为权重的，bias为偏执的\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adamax\")\n",
    "# keras model.compile(loss='目标函数 ', optimizer='adam', metrics=['accuracy'])\n",
    "# loss目标函数，或称损失函数，是网络中的性能函数（mse就是mean_squared_error均方差）\n",
    "# optimizer优化器，用于控制梯度裁剪（sgd为随机梯度下降法，支持动量参数，支持学习衰减率，支持Nesterov动量）\n",
    "\n",
    "model.summary()  # 打印出模型概况，实际调用的是keras.utils.print_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=100,\n",
    "    batch_size=8,\n",
    "    validation_data=(test_features, test_labels),\n",
    ")\n",
    "# train_features：输入数据。一个输入，类型是numpy.array\n",
    "# train_labels：输出数据\n",
    "# batch_size：整数，指定进行梯度下降时每个batch包含的样本数。训练时一个batch的样本会被计算一次梯度下降，使目标函数优化一步。\n",
    "# epochs：整数，训练终止时的epoch值，训练将在达到该epoch值时停止，当没有设置initial_epoch时，它就是训练的总轮数，否则训练的总轮数为epochs - inital_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(myModel.history)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(len(myModel.history[\"loss\"]))\n",
    "\n",
    "plt.figure(dpi=400)\n",
    "plt.plot(epochs, myModel.history[\"loss\"], \"b\", label=\"Training loss\")\n",
    "plt.plot(epochs, myModel.history[\"val_loss\"], \"r\", label=\"Validation val_loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"Traing and Validation loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "test_preds = model.predict(test_features)  # 模型预测，输入测试集，输出预测结果\n",
    "print(\"测试集MSE为:%.5f\" % mean_squared_error(test_labels, test_preds))\n",
    "print(\"测试集R^2:%.5f\" % r2_score(test_labels, test_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "弱学习器 决策树 寻找最优参数组合（随机搜索）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "DeTree = DecisionTreeRegressor(\n",
    "    criterion=\"squared_error\", random_state=30, splitter=\"random\"\n",
    ")\n",
    "\n",
    "# 定义参数分布\n",
    "param_dist = {\n",
    "    \"max_depth\": [4, 5, 6, 7],\n",
    "    \"min_samples_leaf\": np.arange(1, 30),\n",
    "    \"min_samples_split\": np.arange(2, 30),\n",
    "}\n",
    "\n",
    "# 使用随机搜索寻找最优参数组合\n",
    "random_search = RandomizedSearchCV(\n",
    "    DeTree,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=3000,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    ")\n",
    "random_search.fit(train_features, train_labels)\n",
    "\n",
    "# 输出最优参数组合\n",
    "print(\"随机搜索的最优参数组合：\", random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "DeTree = DecisionTreeRegressor(\n",
    "    criterion=\"squared_error\",\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=14,\n",
    "    random_state=30,\n",
    "    splitter=\"random\",\n",
    ")\n",
    "\n",
    "weakClassifier = DeTree.fit(train_features, train_labels)\n",
    "y_pred = weakClassifier.predict(test_features)\n",
    "print(\"测试集MSE值: %0.5f\" % (mean_squared_error(test_labels, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# 创建Adaboost回归模型\n",
    "adaboost = AdaBoostRegressor(estimator=weakClassifier, random_state=32)\n",
    "\n",
    "# 定义参数分布\n",
    "param_dist = {\n",
    "    \"n_estimators\": [243, 244, 245, 246, 247, 248, 249, 250],\n",
    "    \"learning_rate\": np.logspace(-3, 0, 4),\n",
    "    \"loss\": [\"linear\", \"square\", \"exponential\"],\n",
    "}\n",
    "\n",
    "# 使用网格搜索寻找最优参数组合\n",
    "grid_search = GridSearchCV(\n",
    "    adaboost, param_grid=param_dist, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=4\n",
    ")\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "# 输出最优参数组合\n",
    "print(\"最优参数组合:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "adaboost = AdaBoostRegressor(\n",
    "    estimator=weakClassifier,\n",
    "    n_estimators=246,\n",
    "    learning_rate=0.01,\n",
    "    loss=\"exponential\",\n",
    "    random_state=32,\n",
    ")\n",
    "\n",
    "# base_estimator：基础回归模型，默认为DecisionTreeRegressor(max_depth=3)，也可以使用其他的回归模型。\n",
    "# n_estimators：基础回归模型的数量，默认为50。\n",
    "# learning_rate：学习率，默认为1.0。学习率控制每个基础回归模型的权重，在每个迭代中对误差进行调整，以提高模型性能和稳定性。\n",
    "# loss：损失函数，默认为linear。可以选择linear、square或exponential。损失函数用于调整每个基础回归模型的权重。\n",
    "# random_state：随机种子。\n",
    "# 需要注意的是，Adaboost回归模型的参数n_estimators和learning_rate是相互影响的。当基础回归模型数量较多时，学习率应该设置较小以避免过拟合。反之，当基础回归模型数量较少时，学习率可以设置较大以提高模型的性能。\n",
    "\n",
    "# 使用交叉验证评估模型精度\n",
    "scores = cross_val_score(\n",
    "    adaboost, train_features, train_labels, cv=5, scoring=\"neg_mean_squared_error\"\n",
    ")\n",
    "\n",
    "# 计算交叉验证的平均MSE值\n",
    "cv_mse = -scores.mean()\n",
    "print(\"交叉验证MSE值: %0.5f\" % cv_mse)\n",
    "\n",
    "# 训练模型并预测测试集\n",
    "adaboost.fit(train_features, train_labels)\n",
    "y_pred = adaboost.predict(test_features)\n",
    "\n",
    "# 计算测试集的MSE值\n",
    "test_mse = mean_squared_error(test_labels, y_pred)\n",
    "test_r2 = r2_score(test_labels, y_pred)\n",
    "print(\"测试集MSE值: %0.5f\" % test_mse)\n",
    "print(\"测试集R^2值: %0.5f\" % test_r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 创建XGBoost回归模型\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.1, 1.0],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"min_child_weight\": [1, 3, 5],\n",
    "    \"gamma\": [0.0, 0.1, 0.2],\n",
    "    \"subsample\": [0.5, 0.7, 0.9],\n",
    "    \"colsample_bytree\": [0.3, 0.5, 0.7],\n",
    "}\n",
    "\n",
    "# 使用网格搜索寻找最优参数组合\n",
    "grid_search = GridSearchCV(\n",
    "    xgb, param_grid=param_grid, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=4\n",
    ")\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "# 输出最优参数组合\n",
    "print(\"最优参数组合:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "dtrain = xgb.DMatrix(train_features, label=train_labels)\n",
    "dtest = xgb.DMatrix(test_features, label=test_labels)\n",
    "\n",
    "# params:弱评估器(booster)有关的参数\n",
    "params = {\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"gamma\": 0.2,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 3,\n",
    "    \"min_child_weight\": 5,\n",
    "    \"subsample\": 0.9,\n",
    "}\n",
    "num_round = np.arange(30, 51, 1)  # 迭代轮数\n",
    "\n",
    "for i in num_round:\n",
    "    boost = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=i,  # 设置模型参数  # dtrain：训练数据集\n",
    "    )  # 迭代轮数\n",
    "    result = boost.predict(dtest)\n",
    "    print(\n",
    "        \"迭代{}次的均方误差MSE为:{}\".format(i, mean_squared_error(test_labels, result))\n",
    "    )\n",
    "    print(\"迭代{}次的R^2为:{}\".format(i, r2_score(test_labels, result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost 迭代最优：\n",
    "迭代 40 次的均方误差 MSE 为:1.6605730332950106\n",
    "迭代 40 次的 R^2 为:0.11773580292133157\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # 定义模型\n",
    "# model = RandomForestRegressor()\n",
    "\n",
    "# # 定义参数空间\n",
    "# param_dist = {\n",
    "#     'n_estimators': range(50, 100, 5),\n",
    "#     'max_depth': [None] + list(range(1, 14, 2)),\n",
    "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'min_samples_split': list(range(2, 11)),\n",
    "#     'min_samples_leaf': list(range(1, 11)),\n",
    "#     'bootstrap': [True, False],\n",
    "# }\n",
    "\n",
    "# # 定义网格搜索对象\n",
    "# search = GridSearchCV(\n",
    "#     model, param_grid=param_dist, cv=5, scoring='neg_mean_squared_error', n_jobs=4\n",
    "# )\n",
    "\n",
    "# # 进行搜索\n",
    "# search.fit(train_features, train_labels)\n",
    "\n",
    "# # 输出最优参数\n",
    "# print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建Random Forest Regression模型\n",
    "model = RandomForestRegressor(\n",
    "    bootstrap=True,\n",
    "    max_depth=25,\n",
    "    max_features=\"log2\",  # type: ignore\n",
    "    min_samples_leaf=7,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=55,\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model.fit(train_features, train_labels)\n",
    "\n",
    "# 预测测试集结果\n",
    "y_pred = model.predict(test_features)\n",
    "\n",
    "# 计算MSE评分\n",
    "mse = mean_squared_error(test_labels, y_pred)\n",
    "r2 = r2_score(test_labels, y_pred)\n",
    "\n",
    "# 输出MSE评分\n",
    "print(\"MSE得分:{}\".format(mse))\n",
    "print(\"R^2得分:{}\".format(r2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0df9fd8f9b7b6d6419ee17daae1a42e74229fe213e4131614795a5a7eecddb4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
